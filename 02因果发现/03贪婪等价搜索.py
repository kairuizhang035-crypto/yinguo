#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
03 è´ªå©ªç­‰ä»·æœç´¢ (Greedy Equivalence Search - GES)
éäº¤äº’å¼ç‰ˆæœ¬ï¼Œä½¿ç”¨AIC-Dè¯„åˆ†æ ‡å‡†

ä½œè€…: å› æœå‘ç°ç³»ç»Ÿ
æ—¥æœŸ: 2025å¹´
"""

import pandas as pd
import numpy as np
from pgmpy.estimators import GES
import matplotlib.pyplot as plt
import networkx as nx
import os
import time
import json
from datetime import datetime

# è®¾ç½®ä¸­æ–‡å­—ä½“
import matplotlib
matplotlib.rcParams['font.family'] = ['sans-serif']
matplotlib.rcParams['font.sans-serif'] = [
    'SimHei', 'WenQuanYi Micro Hei', 'WenQuanYi Zen Hei', 
    'Noto Sans CJK SC', 'Source Han Sans SC', 'Microsoft YaHei',
    'DejaVu Sans', 'Arial Unicode MS', 'Liberation Sans'
]
matplotlib.rcParams['axes.unicode_minus'] = False

def load_data():
    """åŠ è½½æ•°æ®"""
    input_file = "/home/zkr/å› æœå‘ç°/01æ•°æ®é¢„å¤„ç†/ç¼©å‡æ•°æ®_è§„æ ¼.csv"
    
    # å°è¯•ä½¿ç”¨utf-8ç¼–ç 
    try:
        df = pd.read_csv(input_file, encoding='utf-8', header=0, index_col=0)
    except UnicodeDecodeError:
        try:
            df = pd.read_csv(input_file, encoding='utf-8-sig', header=0, index_col=0)
        except UnicodeDecodeError:
            df = pd.read_csv(input_file, encoding='latin-1', header=0, index_col=0)
    
    df = df.dropna(axis=1, how='all')
    df = df.astype('float32')
    
    print(f"âœ“ æ•°æ®åŠ è½½å®Œæˆ: {df.shape}")
    return df

def create_output_folder():
    """åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹"""
    script_dir = os.path.dirname(os.path.abspath(__file__))
    output_dir = os.path.join(script_dir, "03è´ªå©ªç­‰ä»·æœç´¢ç»“æœ")
    os.makedirs(output_dir, exist_ok=True)
    return output_dir

def save_dag_results(dag, output_folder, df_columns):
    """ä¿å­˜DAGç»“æœåˆ°æ–‡ä»¶"""
    edges = list(dag.edges())
    
    # ä¿å­˜TXTæ ¼å¼
    txt_file = os.path.join(output_folder, "GreedyEquivalence_AIC-D_å› æœè¾¹å®Œæ•´.txt")
    with open(txt_file, 'w', encoding='utf-8') as f:
        f.write("è´ªå©ªç­‰ä»·æœç´¢ (GES-AIC-D) å‘ç°çš„å› æœè¾¹\n")
        f.write("=" * 40 + "\n")
        for i, edge in enumerate(edges, 1):
            f.write(f"{i:3d}. {edge[0]} -> {edge[1]}\n")
    
    # ä¿å­˜CSVæ ¼å¼
    df_edges = pd.DataFrame(edges, columns=["æºèŠ‚ç‚¹", "ç›®æ ‡èŠ‚ç‚¹"])
    csv_file = os.path.join(output_folder, "GreedyEquivalence_AIC-D_å› æœè¾¹åˆ—è¡¨.csv")
    df_edges.to_csv(csv_file, index=False, encoding="utf-8-sig")
    
    # ç”Ÿæˆç½‘ç»œå›¾
    plt.figure(figsize=(16, 12))
    G = nx.DiGraph()
    G.add_edges_from(edges)
    
    pos = nx.spring_layout(G, k=3, iterations=50, seed=42)
    
    # ç»˜åˆ¶èŠ‚ç‚¹
    nx.draw_networkx_nodes(G, pos, 
                          node_color='lightgreen', 
                          node_size=2000,
                          alpha=0.8)
    
    # ç»˜åˆ¶è¾¹
    nx.draw_networkx_edges(G, pos, 
                          edge_color='gray',
                          arrows=True,
                          arrowsize=20,
                          arrowstyle='->',
                          width=1.5,
                          alpha=0.7)
    
    # ç»˜åˆ¶æ ‡ç­¾
    nx.draw_networkx_labels(G, pos, 
                           font_size=10,
                           font_weight='bold',
                           font_family='sans-serif')
    
    plt.title(f"è´ªå©ªç­‰ä»·æœç´¢ (GES-AIC-D) å› æœç½‘ç»œå›¾\nå…±{len(edges)}æ¡å› æœè¾¹", fontsize=16, fontweight='bold')
    plt.axis('off')
    plt.tight_layout()
    
    graph_file = os.path.join(output_folder, "GreedyEquivalence_AIC-D_å› æœç½‘ç»œå›¾.png")
    plt.savefig(graph_file, dpi=300, bbox_inches='tight', 
                facecolor='white', edgecolor='none')
    plt.close()
    
    # åˆ›å»ºè¯¦ç»†JSONç»“æœ
    G = nx.DiGraph()
    G.add_edges_from(edges)
    
    in_degrees = dict(G.in_degree())
    out_degrees = dict(G.out_degree())
    
    results = {
        "ç®—æ³•ä¿¡æ¯": {
            "ç®—æ³•åç§°": "è´ªå©ªç­‰ä»·æœç´¢ (Greedy Equivalence Search - GES)",
            "è¯„åˆ†æ–¹æ³•": "AIC-D (Akaike Information Criterion - Discrete)",
            "ç”Ÿæˆæ—¶é—´": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "æ•°æ®ç»´åº¦": {
                "æ ·æœ¬æ•°": len(df_columns),
                "å˜é‡æ•°": len(df_columns)
            }
        },
        "ç½‘ç»œç»“æ„": {
            "èŠ‚ç‚¹æ€»æ•°": len(dag.nodes()),
            "è¾¹æ€»æ•°": len(edges),
            "èŠ‚ç‚¹åˆ—è¡¨": list(dag.nodes()),
            "å› æœè¾¹åˆ—è¡¨": [{"æºèŠ‚ç‚¹": edge[0], "ç›®æ ‡èŠ‚ç‚¹": edge[1]} for edge in edges]
        },
        "ç»Ÿè®¡ä¿¡æ¯": {
            "å…¥åº¦ç»Ÿè®¡": {node: in_degrees.get(node, 0) for node in dag.nodes()},
            "å‡ºåº¦ç»Ÿè®¡": {node: out_degrees.get(node, 0) for node in dag.nodes()},
            "æœ€å¤§å…¥åº¦": max(in_degrees.values()) if in_degrees else 0,
            "æœ€å¤§å‡ºåº¦": max(out_degrees.values()) if out_degrees else 0,
            "å¹³å‡åº¦æ•°": sum(dict(G.degree()).values()) / len(dag.nodes()) if dag.nodes() else 0
        },
        "èŠ‚ç‚¹åˆ†æ": {
            "æ ¹èŠ‚ç‚¹": [node for node in dag.nodes() if in_degrees.get(node, 0) == 0],
            "å¶èŠ‚ç‚¹": [node for node in dag.nodes() if out_degrees.get(node, 0) == 0],
            "ä¸­ä»‹èŠ‚ç‚¹": [node for node in dag.nodes() if in_degrees.get(node, 0) > 0 and out_degrees.get(node, 0) > 0]
        }
    }
    
    json_file = os.path.join(output_folder, "GreedyEquivalence_AIC-D_å› æœç»“æœ.json")
    with open(json_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    return txt_file, csv_file, graph_file, json_file, results

def run_ges_algorithm():
    """è¿è¡Œè´ªå©ªç­‰ä»·æœç´¢ç®—æ³•"""
    print("=" * 60)
    print("03 è´ªå©ªç­‰ä»·æœç´¢ (GES) - å¼€å§‹æ‰§è¡Œ")
    print("=" * 60)
    
    # 1. åŠ è½½æ•°æ®
    df = load_data()
    
    # 2. åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹
    output_dir = create_output_folder()
    
    # 3. ä½¿ç”¨AIC-Dè¯„åˆ†æ–¹æ³•è¿è¡ŒGESç®—æ³•
    print("æ­£åœ¨è¿è¡Œè´ªå©ªç­‰ä»·æœç´¢ (GES-AIC-Dè¯„åˆ†)...")
    start_time = time.time()
    
    try:
        ges = GES(df)
        dag = ges.estimate(scoring_method='aic-d')
        
        end_time = time.time()
        execution_time = end_time - start_time
        
        print(f"âœ“ è´ªå©ªç­‰ä»·æœç´¢å®Œæˆï¼Œè€—æ—¶: {execution_time:.2f}ç§’")
        print(f"âœ“ å‘ç° {len(dag.edges())} æ¡å› æœè¾¹")
        
        # 4. ä¿å­˜ç»“æœ
        txt_file, csv_file, graph_file, json_file, results = save_dag_results(dag, output_dir, df.columns)
        
        # 5. è¾“å‡ºç»“æœæ‘˜è¦
        print("\n" + "=" * 60)
        print("è´ªå©ªç­‰ä»·æœç´¢æ‰§è¡Œå®Œæˆ - ç»“æœæ‘˜è¦")
        print("=" * 60)
        print(f"è¯„åˆ†æ–¹æ³•: AIC-D")
        print(f"æ‰§è¡Œæ—¶é—´: {execution_time:.2f}ç§’")
        print(f"æ•°æ®ç»´åº¦: {df.shape[0]} Ã— {df.shape[1]}")
        print(f"å‘ç°çš„å› æœè¾¹æ•°é‡: {results['ç½‘ç»œç»“æ„']['è¾¹æ€»æ•°']}")
        print(f"ç½‘ç»œèŠ‚ç‚¹æ•°é‡: {results['ç½‘ç»œç»“æ„']['èŠ‚ç‚¹æ€»æ•°']}")
        print(f"æ ¹èŠ‚ç‚¹æ•°é‡: {len(results['èŠ‚ç‚¹åˆ†æ']['æ ¹èŠ‚ç‚¹'])}")
        print(f"å¶èŠ‚ç‚¹æ•°é‡: {len(results['èŠ‚ç‚¹åˆ†æ']['å¶èŠ‚ç‚¹'])}")
        print(f"ä¸­ä»‹èŠ‚ç‚¹æ•°é‡: {len(results['èŠ‚ç‚¹åˆ†æ']['ä¸­ä»‹èŠ‚ç‚¹'])}")
        print(f"å¹³å‡èŠ‚ç‚¹åº¦æ•°: {results['ç»Ÿè®¡ä¿¡æ¯']['å¹³å‡åº¦æ•°']:.2f}")
        
        print(f"\nğŸ“ ç»“æœä¿å­˜ä½ç½®:")
        print(f"  - TXTæ–‡ä»¶: {txt_file}")
        print(f"  - CSVæ–‡ä»¶: {csv_file}")
        print(f"  - ç½‘ç»œå›¾: {graph_file}")
        print(f"  - JSONç»“æœ: {json_file}")
        
        return output_dir, len(dag.edges())
        
    except Exception as e:
        print(f"âŒ è´ªå©ªç­‰ä»·æœç´¢æ‰§è¡Œå¤±è´¥: {str(e)}")
        raise

if __name__ == "__main__":
    try:
        output_dir, edge_count = run_ges_algorithm()
        print(f"\nâœ… 03 è´ªå©ªç­‰ä»·æœç´¢æ‰§è¡ŒæˆåŠŸï¼å‘ç° {edge_count} æ¡å› æœè¾¹")
    except Exception as e:
        print(f"\nâŒ 03 è´ªå©ªç­‰ä»·æœç´¢æ‰§è¡Œå¤±è´¥: {str(e)}")
        raise