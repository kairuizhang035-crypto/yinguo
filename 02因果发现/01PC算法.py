#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
01 PCç®—æ³• (åŸºäºçº¦æŸçš„ä¼°è®¡å™¨)
éäº¤äº’å¼ç‰ˆæœ¬ï¼Œç”¨äºç»Ÿä¸€æ‰§è¡Œæµç¨‹

ä½œè€…: å› æœå‘ç°ç³»ç»Ÿ
æ—¥æœŸ: 2025å¹´
"""

import pandas as pd
import os
import json
import matplotlib.pyplot as plt
import networkx as nx
from datetime import datetime
import numpy as np
from pgmpy.estimators import PC

# è®¾ç½®ä¸­æ–‡å­—ä½“
import matplotlib
matplotlib.rcParams['font.family'] = ['sans-serif']
matplotlib.rcParams['font.sans-serif'] = [
    'SimHei', 'WenQuanYi Micro Hei', 'WenQuanYi Zen Hei', 
    'Noto Sans CJK SC', 'Source Han Sans SC', 'Microsoft YaHei',
    'DejaVu Sans', 'Arial Unicode MS', 'Liberation Sans'
]
matplotlib.rcParams['axes.unicode_minus'] = False

def load_data():
    """åŠ è½½æ•°æ®"""
    input_file = "/home/zkr/å› æœå‘ç°/01æ•°æ®é¢„å¤„ç†/ç¼©å‡æ•°æ®_è§„æ ¼.csv"
    
    # å°è¯•ä½¿ç”¨utf-8ç¼–ç 
    try:
        df = pd.read_csv(input_file, encoding='utf-8', header=0, index_col=0)
    except UnicodeDecodeError:
        try:
            df = pd.read_csv(input_file, encoding='utf-8-sig', header=0, index_col=0)
        except UnicodeDecodeError:
            df = pd.read_csv(input_file, encoding='latin-1', header=0, index_col=0)
    
    df = df.dropna(axis=1, how='all')
    df = df.astype('float32')
    
    print(f"âœ“ æ•°æ®åŠ è½½å®Œæˆ: {df.shape}")
    return df

def create_output_folder():
    """åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹"""
    script_dir = os.path.dirname(os.path.abspath(__file__))
    output_dir = os.path.join(script_dir, "01PCç®—æ³•ç»“æœ")
    os.makedirs(output_dir, exist_ok=True)
    return output_dir

def create_causal_network_graph(edges, output_dir):
    """åˆ›å»ºå› æœç½‘ç»œå›¾å¹¶ä¿å­˜ä¸ºPNG"""
    G = nx.DiGraph()
    
    # æ·»åŠ è¾¹
    for edge in edges:
        G.add_edge(edge[0], edge[1])
    
    plt.figure(figsize=(16, 12))
    
    # ä½¿ç”¨springå¸ƒå±€
    pos = nx.spring_layout(G, k=3, iterations=50, seed=42)
    
    # ç»˜åˆ¶èŠ‚ç‚¹
    nx.draw_networkx_nodes(G, pos, 
                          node_color='lightblue', 
                          node_size=2000,
                          alpha=0.8)
    
    # ç»˜åˆ¶è¾¹
    nx.draw_networkx_edges(G, pos, 
                          edge_color='gray',
                          arrows=True,
                          arrowsize=20,
                          arrowstyle='->',
                          width=1.5,
                          alpha=0.7)
    
    # ç»˜åˆ¶æ ‡ç­¾
    nx.draw_networkx_labels(G, pos, 
                           font_size=10,
                           font_weight='bold',
                           font_family='sans-serif')
    
    plt.title(f"PCç®—æ³•å› æœç½‘ç»œå›¾\nå…±{len(edges)}æ¡å› æœè¾¹", fontsize=16, fontweight='bold')
    plt.axis('off')
    plt.tight_layout()
    
    graph_file = os.path.join(output_dir, "PC_å› æœç½‘ç»œå›¾.png")
    plt.savefig(graph_file, dpi=300, bbox_inches='tight', 
                facecolor='white', edgecolor='none')
    plt.close()
    
    return graph_file

def create_detailed_json_results(estimated_model, df, output_dir):
    """åˆ›å»ºè¯¦ç»†çš„å› æœå‘ç°ç»“æœJSONæ–‡ä»¶"""
    nodes = list(estimated_model.nodes())
    edges = list(estimated_model.edges())
    
    # è®¡ç®—ç½‘ç»œç»Ÿè®¡ä¿¡æ¯
    G = nx.DiGraph()
    G.add_edges_from(edges)
    
    # èŠ‚ç‚¹åº¦æ•°ç»Ÿè®¡
    in_degrees = dict(G.in_degree())
    out_degrees = dict(G.out_degree())
    
    # åˆ›å»ºè¯¦ç»†ç»“æœå­—å…¸
    results = {
        "ç®—æ³•ä¿¡æ¯": {
            "ç®—æ³•åç§°": "PCç®—æ³•",
            "ç”Ÿæˆæ—¶é—´": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "æ•°æ®ç»´åº¦": {
                "æ ·æœ¬æ•°": int(df.shape[0]),
                "å˜é‡æ•°": int(df.shape[1])
            },
            "å‚æ•°è®¾ç½®": {
                "ç‹¬ç«‹æ€§æ£€éªŒ": "chi_square",
                "æ˜¾è‘—æ€§æ°´å¹³": 0.05,
                "å˜ä½“": "stable"
            }
        },
        "ç½‘ç»œç»“æ„": {
            "èŠ‚ç‚¹æ€»æ•°": len(nodes),
            "è¾¹æ€»æ•°": len(edges),
            "èŠ‚ç‚¹åˆ—è¡¨": nodes,
            "å› æœè¾¹åˆ—è¡¨": [{"æºèŠ‚ç‚¹": edge[0], "ç›®æ ‡èŠ‚ç‚¹": edge[1]} for edge in edges]
        },
        "ç»Ÿè®¡ä¿¡æ¯": {
            "å…¥åº¦ç»Ÿè®¡": {node: in_degrees.get(node, 0) for node in nodes},
            "å‡ºåº¦ç»Ÿè®¡": {node: out_degrees.get(node, 0) for node in nodes},
            "æœ€å¤§å…¥åº¦": max(in_degrees.values()) if in_degrees else 0,
            "æœ€å¤§å‡ºåº¦": max(out_degrees.values()) if out_degrees else 0,
            "å¹³å‡åº¦æ•°": sum(dict(G.degree()).values()) / len(nodes) if nodes else 0
        },
        "èŠ‚ç‚¹åˆ†æ": {
            "æ ¹èŠ‚ç‚¹": [node for node in nodes if in_degrees.get(node, 0) == 0],
            "å¶èŠ‚ç‚¹": [node for node in nodes if out_degrees.get(node, 0) == 0],
            "ä¸­ä»‹èŠ‚ç‚¹": [node for node in nodes if in_degrees.get(node, 0) > 0 and out_degrees.get(node, 0) > 0]
        }
    }
    
    # ä¿å­˜JSONæ–‡ä»¶
    json_file = os.path.join(output_dir, "PC_å› æœç»“æœ.json")
    with open(json_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    return json_file, results

def run_pc_algorithm():
    """è¿è¡ŒPCç®—æ³•"""
    print("=" * 60)
    print("01 PCç®—æ³• (åŸºäºçº¦æŸçš„ä¼°è®¡å™¨) - å¼€å§‹æ‰§è¡Œ")
    print("=" * 60)
    
    # 1. åŠ è½½æ•°æ®
    df = load_data()
    
    # 2. åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹
    output_dir = create_output_folder()
    
    # 3. åˆå§‹åŒ–PCç®—æ³•ä¼°è®¡å™¨
    print("æ­£åœ¨è¿è¡ŒPCç®—æ³•...")
    est = PC(data=df)
    
    # 4. è¿è¡Œä¼°è®¡ç®—æ³•
    estimated_model = est.estimate(variant="stable", ci_test="chi_square", significance_level=0.05)
    
    # 5. è·å–ç»“æœ
    edges_list = list(estimated_model.edges())
    print(f"âœ“ PCç®—æ³•å®Œæˆï¼Œå‘ç° {len(edges_list)} æ¡å› æœè¾¹")
    
    # 6. ä¿å­˜ç»“æœæ–‡ä»¶
    # ä¿å­˜TXTæ ¼å¼
    output_file_txt = os.path.join(output_dir, "PC_å› æœè¾¹å®Œæ•´.txt")
    with open(output_file_txt, 'w', encoding='utf-8') as f:
        f.write("PCç®—æ³•å‘ç°çš„å› æœè¾¹\n")
        f.write("=" * 30 + "\n")
        for i, edge in enumerate(edges_list, 1):
            f.write(f"{i:3d}. {edge[0]} -> {edge[1]}\n")
    
    # ä¿å­˜CSVæ ¼å¼
    df_edges = pd.DataFrame(edges_list, columns=["æºèŠ‚ç‚¹", "ç›®æ ‡èŠ‚ç‚¹"])
    output_file_csv = os.path.join(output_dir, "PC_å› æœè¾¹åˆ—è¡¨.csv")
    df_edges.to_csv(output_file_csv, index=False, encoding="utf-8-sig")
    
    # 7. ç”Ÿæˆç½‘ç»œå›¾
    print("æ­£åœ¨ç”Ÿæˆå› æœç½‘ç»œå›¾...")
    graph_file = create_causal_network_graph(edges_list, output_dir)
    
    # 8. ç”ŸæˆJSONç»“æœ
    print("æ­£åœ¨ç”Ÿæˆè¯¦ç»†JSONç»“æœ...")
    json_file, results = create_detailed_json_results(estimated_model, df, output_dir)
    
    # 9. è¾“å‡ºç»“æœæ‘˜è¦
    print("\n" + "=" * 60)
    print("PCç®—æ³•æ‰§è¡Œå®Œæˆ - ç»“æœæ‘˜è¦")
    print("=" * 60)
    print(f"æ•°æ®ç»´åº¦: {results['ç®—æ³•ä¿¡æ¯']['æ•°æ®ç»´åº¦']['æ ·æœ¬æ•°']} Ã— {results['ç®—æ³•ä¿¡æ¯']['æ•°æ®ç»´åº¦']['å˜é‡æ•°']}")
    print(f"å‘ç°çš„å› æœè¾¹æ•°é‡: {results['ç½‘ç»œç»“æ„']['è¾¹æ€»æ•°']}")
    print(f"ç½‘ç»œèŠ‚ç‚¹æ•°é‡: {results['ç½‘ç»œç»“æ„']['èŠ‚ç‚¹æ€»æ•°']}")
    print(f"æ ¹èŠ‚ç‚¹æ•°é‡: {len(results['èŠ‚ç‚¹åˆ†æ']['æ ¹èŠ‚ç‚¹'])}")
    print(f"å¶èŠ‚ç‚¹æ•°é‡: {len(results['èŠ‚ç‚¹åˆ†æ']['å¶èŠ‚ç‚¹'])}")
    print(f"ä¸­ä»‹èŠ‚ç‚¹æ•°é‡: {len(results['èŠ‚ç‚¹åˆ†æ']['ä¸­ä»‹èŠ‚ç‚¹'])}")
    print(f"å¹³å‡èŠ‚ç‚¹åº¦æ•°: {results['ç»Ÿè®¡ä¿¡æ¯']['å¹³å‡åº¦æ•°']:.2f}")
    
    print(f"\nğŸ“ ç»“æœä¿å­˜ä½ç½®:")
    print(f"  - TXTæ–‡ä»¶: {output_file_txt}")
    print(f"  - CSVæ–‡ä»¶: {output_file_csv}")
    print(f"  - ç½‘ç»œå›¾: {graph_file}")
    print(f"  - JSONç»“æœ: {json_file}")
    
    return output_dir, len(edges_list)

if __name__ == "__main__":
    try:
        output_dir, edge_count = run_pc_algorithm()
        print(f"\nâœ… 01 PCç®—æ³•æ‰§è¡ŒæˆåŠŸï¼å‘ç° {edge_count} æ¡å› æœè¾¹")
    except Exception as e:
        print(f"\nâŒ 01 PCç®—æ³•æ‰§è¡Œå¤±è´¥: {str(e)}")
        raise