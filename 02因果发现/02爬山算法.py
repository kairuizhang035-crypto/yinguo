#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
02 çˆ¬å±±ç®—æ³• (Hill Climbing Search)
éäº¤äº’å¼ç‰ˆæœ¬ï¼Œä½¿ç”¨AIC-Dè¯„åˆ†æ ‡å‡†

ä½œè€…: å› æœå‘ç°ç³»ç»Ÿ
æ—¥æœŸ: 2025å¹´
"""

import pandas as pd
import numpy as np
from pgmpy.estimators import HillClimbSearch
from pgmpy.models import BayesianNetwork
from pgmpy.estimators import MaximumLikelihoodEstimator
import matplotlib.pyplot as plt
import networkx as nx
import os
import time
import json
from datetime import datetime

# è®¾ç½®ä¸­æ–‡å­—ä½“
import matplotlib
matplotlib.rcParams['font.family'] = ['sans-serif']
matplotlib.rcParams['font.sans-serif'] = [
    'SimHei', 'WenQuanYi Micro Hei', 'WenQuanYi Zen Hei', 
    'Noto Sans CJK SC', 'Source Han Sans SC', 'Microsoft YaHei',
    'DejaVu Sans', 'Arial Unicode MS', 'Liberation Sans'
]
matplotlib.rcParams['axes.unicode_minus'] = False

def load_data():
    """åŠ è½½æ•°æ®"""
    input_file = "/home/zkr/å› æœå‘ç°/01æ•°æ®é¢„å¤„ç†/ç¼©å‡æ•°æ®_è§„æ ¼.csv"
    
    # å°è¯•ä½¿ç”¨utf-8ç¼–ç 
    try:
        df = pd.read_csv(input_file, encoding='utf-8', header=0, index_col=0)
    except UnicodeDecodeError:
        try:
            df = pd.read_csv(input_file, encoding='utf-8-sig', header=0, index_col=0)
        except UnicodeDecodeError:
            df = pd.read_csv(input_file, encoding='latin-1', header=0, index_col=0)
    
    df = df.dropna(axis=1, how='all')
    df = df.astype('float32')
    
    print(f"âœ“ æ•°æ®åŠ è½½å®Œæˆ: {df.shape}")
    return df

def create_output_folder():
    """åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹"""
    script_dir = os.path.dirname(os.path.abspath(__file__))
    output_dir = os.path.join(script_dir, "02çˆ¬å±±ç®—æ³•ç»“æœ")
    os.makedirs(output_dir, exist_ok=True)
    return output_dir

def save_dag_results(dag, output_folder, df_columns):
    """ä¿å­˜DAGç»“æœåˆ°æ–‡ä»¶"""
    edges = list(dag.edges())
    
    # ä¿å­˜TXTæ ¼å¼
    txt_file = os.path.join(output_folder, "HillClimbing_AIC-D_å› æœè¾¹å®Œæ•´.txt")
    with open(txt_file, 'w', encoding='utf-8') as f:
        f.write("çˆ¬å±±ç®—æ³• (AIC-D) å‘ç°çš„å› æœè¾¹\n")
        f.write("=" * 40 + "\n")
        for i, edge in enumerate(edges, 1):
            f.write(f"{i:3d}. {edge[0]} -> {edge[1]}\n")
    
    # ä¿å­˜CSVæ ¼å¼
    df_edges = pd.DataFrame(edges, columns=["æºèŠ‚ç‚¹", "ç›®æ ‡èŠ‚ç‚¹"])
    csv_file = os.path.join(output_folder, "HillClimbing_AIC-D_å› æœè¾¹åˆ—è¡¨.csv")
    df_edges.to_csv(csv_file, index=False, encoding="utf-8-sig")
    
    # ç”Ÿæˆç½‘ç»œå›¾
    plt.figure(figsize=(16, 12))
    G = nx.DiGraph()
    G.add_edges_from(edges)
    
    pos = nx.spring_layout(G, k=3, iterations=50, seed=42)
    
    # ç»˜åˆ¶èŠ‚ç‚¹
    nx.draw_networkx_nodes(G, pos, 
                          node_color='lightcoral', 
                          node_size=2000,
                          alpha=0.8)
    
    # ç»˜åˆ¶è¾¹
    nx.draw_networkx_edges(G, pos, 
                          edge_color='gray',
                          arrows=True,
                          arrowsize=20,
                          arrowstyle='->',
                          width=1.5,
                          alpha=0.7)
    
    # ç»˜åˆ¶æ ‡ç­¾
    nx.draw_networkx_labels(G, pos, 
                           font_size=10,
                           font_weight='bold',
                           font_family='sans-serif')
    
    plt.title(f"çˆ¬å±±ç®—æ³• (AIC-D) å› æœç½‘ç»œå›¾\nå…±{len(edges)}æ¡å› æœè¾¹", fontsize=16, fontweight='bold')
    plt.axis('off')
    plt.tight_layout()
    
    graph_file = os.path.join(output_folder, "HillClimbing_AIC-D_å› æœç½‘ç»œå›¾.png")
    plt.savefig(graph_file, dpi=300, bbox_inches='tight', 
                facecolor='white', edgecolor='none')
    plt.close()
    
    # åˆ›å»ºè¯¦ç»†JSONç»“æœ
    G = nx.DiGraph()
    G.add_edges_from(edges)
    
    in_degrees = dict(G.in_degree())
    out_degrees = dict(G.out_degree())
    
    results = {
        "ç®—æ³•ä¿¡æ¯": {
            "ç®—æ³•åç§°": "çˆ¬å±±ç®—æ³• (Hill Climbing Search)",
            "è¯„åˆ†æ–¹æ³•": "AIC-D (Akaike Information Criterion - Discrete)",
            "ç”Ÿæˆæ—¶é—´": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "æ•°æ®ç»´åº¦": {
                "æ ·æœ¬æ•°": len(df_columns),
                "å˜é‡æ•°": len(df_columns)
            }
        },
        "ç½‘ç»œç»“æ„": {
            "èŠ‚ç‚¹æ€»æ•°": len(dag.nodes()),
            "è¾¹æ€»æ•°": len(edges),
            "èŠ‚ç‚¹åˆ—è¡¨": list(dag.nodes()),
            "å› æœè¾¹åˆ—è¡¨": [{"æºèŠ‚ç‚¹": edge[0], "ç›®æ ‡èŠ‚ç‚¹": edge[1]} for edge in edges]
        },
        "ç»Ÿè®¡ä¿¡æ¯": {
            "å…¥åº¦ç»Ÿè®¡": {node: in_degrees.get(node, 0) for node in dag.nodes()},
            "å‡ºåº¦ç»Ÿè®¡": {node: out_degrees.get(node, 0) for node in dag.nodes()},
            "æœ€å¤§å…¥åº¦": max(in_degrees.values()) if in_degrees else 0,
            "æœ€å¤§å‡ºåº¦": max(out_degrees.values()) if out_degrees else 0,
            "å¹³å‡åº¦æ•°": sum(dict(G.degree()).values()) / len(dag.nodes()) if dag.nodes() else 0
        },
        "èŠ‚ç‚¹åˆ†æ": {
            "æ ¹èŠ‚ç‚¹": [node for node in dag.nodes() if in_degrees.get(node, 0) == 0],
            "å¶èŠ‚ç‚¹": [node for node in dag.nodes() if out_degrees.get(node, 0) == 0],
            "ä¸­ä»‹èŠ‚ç‚¹": [node for node in dag.nodes() if in_degrees.get(node, 0) > 0 and out_degrees.get(node, 0) > 0]
        }
    }
    
    json_file = os.path.join(output_folder, "HillClimbing_AIC-D_å› æœç»“æœ.json")
    with open(json_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    return txt_file, csv_file, graph_file, json_file, results

def run_hillclimbing_algorithm():
    """è¿è¡Œçˆ¬å±±ç®—æ³•"""
    print("=" * 60)
    print("02 çˆ¬å±±ç®—æ³• (Hill Climbing Search) - å¼€å§‹æ‰§è¡Œ")
    print("=" * 60)
    
    # 1. åŠ è½½æ•°æ®
    df = load_data()
    
    # 2. åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹
    output_dir = create_output_folder()
    
    # 3. ä½¿ç”¨AIC-Dè¯„åˆ†æ–¹æ³•è¿è¡Œçˆ¬å±±ç®—æ³•
    print("æ­£åœ¨è¿è¡Œçˆ¬å±±ç®—æ³• (AIC-Dè¯„åˆ†)...")
    start_time = time.time()
    
    try:
        hc = HillClimbSearch(df)
        dag = hc.estimate(scoring_method='aic-d')
        
        end_time = time.time()
        execution_time = end_time - start_time
        
        print(f"âœ“ çˆ¬å±±ç®—æ³•å®Œæˆï¼Œè€—æ—¶: {execution_time:.2f}ç§’")
        print(f"âœ“ å‘ç° {len(dag.edges())} æ¡å› æœè¾¹")
        
        # 4. ä¿å­˜ç»“æœ
        txt_file, csv_file, graph_file, json_file, results = save_dag_results(dag, output_dir, df.columns)
        
        # 5. è¾“å‡ºç»“æœæ‘˜è¦
        print("\n" + "=" * 60)
        print("çˆ¬å±±ç®—æ³•æ‰§è¡Œå®Œæˆ - ç»“æœæ‘˜è¦")
        print("=" * 60)
        print(f"è¯„åˆ†æ–¹æ³•: AIC-D")
        print(f"æ‰§è¡Œæ—¶é—´: {execution_time:.2f}ç§’")
        print(f"æ•°æ®ç»´åº¦: {df.shape[0]} Ã— {df.shape[1]}")
        print(f"å‘ç°çš„å› æœè¾¹æ•°é‡: {results['ç½‘ç»œç»“æ„']['è¾¹æ€»æ•°']}")
        print(f"ç½‘ç»œèŠ‚ç‚¹æ•°é‡: {results['ç½‘ç»œç»“æ„']['èŠ‚ç‚¹æ€»æ•°']}")
        print(f"æ ¹èŠ‚ç‚¹æ•°é‡: {len(results['èŠ‚ç‚¹åˆ†æ']['æ ¹èŠ‚ç‚¹'])}")
        print(f"å¶èŠ‚ç‚¹æ•°é‡: {len(results['èŠ‚ç‚¹åˆ†æ']['å¶èŠ‚ç‚¹'])}")
        print(f"ä¸­ä»‹èŠ‚ç‚¹æ•°é‡: {len(results['èŠ‚ç‚¹åˆ†æ']['ä¸­ä»‹èŠ‚ç‚¹'])}")
        print(f"å¹³å‡èŠ‚ç‚¹åº¦æ•°: {results['ç»Ÿè®¡ä¿¡æ¯']['å¹³å‡åº¦æ•°']:.2f}")
        
        print(f"\nğŸ“ ç»“æœä¿å­˜ä½ç½®:")
        print(f"  - TXTæ–‡ä»¶: {txt_file}")
        print(f"  - CSVæ–‡ä»¶: {csv_file}")
        print(f"  - ç½‘ç»œå›¾: {graph_file}")
        print(f"  - JSONç»“æœ: {json_file}")
        
        return output_dir, len(dag.edges())
        
    except Exception as e:
        print(f"âŒ çˆ¬å±±ç®—æ³•æ‰§è¡Œå¤±è´¥: {str(e)}")
        raise

if __name__ == "__main__":
    try:
        output_dir, edge_count = run_hillclimbing_algorithm()
        print(f"\nâœ… 02 çˆ¬å±±ç®—æ³•æ‰§è¡ŒæˆåŠŸï¼å‘ç° {edge_count} æ¡å› æœè¾¹")
    except Exception as e:
        print(f"\nâŒ 02 çˆ¬å±±ç®—æ³•æ‰§è¡Œå¤±è´¥: {str(e)}")
        raise